# GPU Constraint Report: NVIDIA GeForce RTX 3070 Ti

**Generated:** 2026-01-19T00:14:28.099181

## GPU Information

| Property | Value |
|----------|-------|
| GPU Name | NVIDIA GeForce RTX 3070 Ti |
| Total VRAM | 7.66 GB |
| Compute Capability | SM 8.6 |
| CUDA Version | 12.8 |
| Driver Version | 570.195.03 |

## Model Constraints

| Model | Precision | Max Batch | VRAM (MB) | Latency (ms) | OOM Batch | Notes |
|-------|-----------|-----------|-----------|--------------|-----------|-------|
| ResNet50 | fp32 | 256 | 2802 | 243.2 | - | Standard ImageNet model, batch inference |
| ResNet50 | fp16 | 256 | 1505 | 133.0 | - | Half precision, faster inference |
| ViT-Base-16 | fp32 | 256 | 2411 | 894.3 | - | Vision Transformer, larger memory footprint than C... |
| ViT-Base-16 | fp16 | 256 | 1220 | 255.8 | - | Half precision Vision Transformer |
| YOLO-Pose-v11n | fp16 | 128 | 3019 | 556.0 | - | YOLOv11 nano pose detection model, 640x640 input |
| Llama-7B | fp16 | 0 | 0 | N/A | 1 | WILL NOT FIT. Requires ~16GB, available: 7.7GB |
| Llama-7B | int8 | 0 | 0 | N/A | 1 | WILL NOT FIT. Requires ~8.5GB, available: 7.7GB |
| Llama-7B | int4 | 8 | 5120 | N/A | 2 | Estimated to fit. Model: ~3.5GB, Inference: ~5GB |

## Recommendations

- üî¥ CRITICAL: NVIDIA GeForce RTX 3070 Ti has limited VRAM (7.7GB). Use quantized models (INT8/INT4) for LLMs.
- ‚úÖ ResNet50 (fp32): Max batch=256 (2802MB)
- ‚úÖ ResNet50 (fp16): Max batch=256 (1505MB)
- ‚úÖ ViT-Base-16 (fp32): Max batch=256 (2411MB)
- ‚úÖ ViT-Base-16 (fp16): Max batch=256 (1220MB)
- ‚úÖ YOLO-Pose-v11n (fp16): Max batch=128 (3019MB)
- ‚ùå Llama-7B (fp16): FAILS on this GPU. Reason: WILL NOT FIT. Requires ~16GB, available: 7.7GB
- ‚ùå Llama-7B (int8): FAILS on this GPU. Reason: WILL NOT FIT. Requires ~8.5GB, available: 7.7GB
- ‚ö†Ô∏è Llama-7B (int4): Max batch=8, OOM at batch=2

---

*Generated by gpu_constraint_profiler.py*