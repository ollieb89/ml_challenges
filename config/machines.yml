machines:
  desktop-5070ti:
    name: "Main Dev Machine"
    gpu: "RTX 5070 Ti"
    vram_gb: 12
    cuda_sm: "90"
    primary: true
    use_for: ["development", "inference", "testing"]
    environment: cuda

  laptop-4070ti:
    name: "Training Laptop"
    gpu: "RTX 4070 Ti Mobile"
    vram_gb: 12
    cuda_sm: "89"
    primary: false
    use_for: ["training", "optimization"]
    environment: cuda
    power_limit: 90  # TDP limit for laptop
    # SSH Configuration
    ssh_host: "192.168.1.X"  # UPDATE THIS
    ssh_user: "ollie"        # UPDATE THIS
    remote_root: "~/ai-ml-pipeline"

  pc-3070ti:
    name: "Secondary PC"
    gpu: "RTX 3070 Ti"
    vram_gb: 8
    cuda_sm: "86"
    primary: false
    use_for: ["backup", "inference", "testing"]
    environment: cuda
    batch_size_limit: 32  # More constrained
    # SSH Configuration
    ssh_host: "192.168.1.211"  # UPDATE THIS
    ssh_user: "ollie"        # UPDATE THIS
    remote_root: "~/ai-ml-pipeline"